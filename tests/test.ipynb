{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_percentile(x: list, k: int):\n",
    "    import numpy as np\n",
    "    n = len(x)\n",
    "\n",
    "    if n > 100:\n",
    "        p = np.percentile(x, k)\n",
    "    else:\n",
    "        x = sorted(x)\n",
    "        i = (k / 100) * (n - 1)\n",
    "        j = int(i)\n",
    "\n",
    "        if i == j:\n",
    "            p = x[j]\n",
    "        else: \n",
    "            p = x[j] + (i - j) * (x[j + 1] - x[j])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.984999999999999"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,7,2,6]\n",
    "k = 99.5\n",
    "p = cal_percentile(x, k)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_dict_to_json(file_path, data):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(json.dumps(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': [1, 7, 2, 6], '1235465': [1, 7, 2, 6, 1, 7, 2, 6]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_json(file_path):\n",
    "    with open(file_path, 'rb') as file:  # Mở file dưới dạng nhị phân\n",
    "        return json.loads(file.read())  # Đọc và chuyển đổi từ bytes thành Python object\n",
    "\n",
    "# Đọc file JSON\n",
    "file_path = 'output.json'\n",
    "data = read_json(file_path)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './output.json'\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = json.loads(file.read()) \n",
    "    data = {int(k): v for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{123546: [1.0, 7.0, 2.0, 6.0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{int(k): v for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "{'order45612313123': {'product': 'Laptop', 'price': 1200}, 'pr4234242oduct789': {'category': 'Electronics'}, 'order456': {'product': 'Laptop', 'price': 1200}, '1': {'name': 'Alice', 'age': 25}, '2': {'product': 'Laptop', 'price': 1200}, 'user123': {'name': 'Alice', 'age': 26}, 'product789': {'category': 'Electronics'}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import hashlib\n",
    "import bisect\n",
    "import os\n",
    "\n",
    "class PickleShardManager:\n",
    "    def __init__(self, num_shards=3, folder=\"data_shards\"):\n",
    "        self.num_shards = num_shards\n",
    "        self.folder = folder\n",
    "        self.metadata_file = f\"{folder}/metadata.pkl\"  # File lưu metadata\n",
    "        self.shard_keys = []\n",
    "        self.shards = {}\n",
    "        self.metadata = {}\n",
    "\n",
    "        os.makedirs(folder, exist_ok=True)  # Tạo folder nếu chưa có\n",
    "\n",
    "        # Tạo các file shard với hash key\n",
    "        for i in range(num_shards):\n",
    "            shard_key = self._hash(f\"shard-{i}\")  # Hash để phân bố shard\n",
    "            self.shard_keys.append(shard_key)\n",
    "            self.shards[shard_key] = f\"{folder}/shard_{i}.pkl\"\n",
    "\n",
    "        self.shard_keys.sort()  # Sắp xếp để dùng `bisect`\n",
    "\n",
    "        # Load metadata nếu có\n",
    "        self._load_metadata()\n",
    "\n",
    "    def _hash(self, key):\n",
    "        \"\"\"Tạo hash integer từ key\"\"\"\n",
    "        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n",
    "\n",
    "    def _get_shard_file(self, key):\n",
    "        \"\"\"Tìm file pickle phù hợp cho key\"\"\"\n",
    "        key_hash = self._hash(key)\n",
    "        idx = bisect.bisect(self.shard_keys, key_hash) % self.num_shards\n",
    "        return self.shards[self.shard_keys[idx]]\n",
    "\n",
    "    def _save_metadata(self):\n",
    "        \"\"\"Lưu metadata vào file\"\"\"\n",
    "        with open(self.metadata_file, \"wb\") as f:\n",
    "            pickle.dump(self.metadata, f)\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Tải metadata từ file nếu tồn tại\"\"\"\n",
    "        if os.path.exists(self.metadata_file):\n",
    "            with open(self.metadata_file, \"rb\") as f:\n",
    "                self.metadata = pickle.load(f)\n",
    "\n",
    "    def save(self, key, data):\n",
    "        \"\"\"Lưu dict vào file pickle phù hợp và cập nhật metadata\"\"\"\n",
    "        file_path = self._get_shard_file(key)\n",
    "\n",
    "        # Cập nhật metadata\n",
    "        self.metadata[key] = file_path\n",
    "        self._save_metadata()\n",
    "\n",
    "        # Lưu vào file pickle\n",
    "        with open(file_path, \"ab\") as f:\n",
    "            pickle.dump({key: data}, f)\n",
    "\n",
    "    def exists(self, key):\n",
    "        \"\"\"Kiểm tra nhanh xem key có tồn tại không\"\"\"\n",
    "        return key in self.metadata  # Kiểm tra ngay trong metadata\n",
    "\n",
    "    def update(self, key, new_data):\n",
    "        \"\"\"Cập nhật dữ liệu của một key\"\"\"\n",
    "        if key not in self.metadata:\n",
    "            raise KeyError(f\"Key '{key}' không tồn tại!\")\n",
    "\n",
    "        file_path = self.metadata[key]\n",
    "\n",
    "        # Đọc toàn bộ dữ liệu từ file shard\n",
    "        data = self.load_shard(file_path)\n",
    "        data[key] = new_data  # Cập nhật giá trị\n",
    "\n",
    "        # Ghi đè lại file với dữ liệu mới\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def load_shard(self, file_path):\n",
    "        \"\"\"Đọc toàn bộ dữ liệu từ một shard\"\"\"\n",
    "        data = {}\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                while True:\n",
    "                    try:\n",
    "                        record = pickle.load(f)\n",
    "                        data.update(record)\n",
    "                    except EOFError:\n",
    "                        break\n",
    "        return data\n",
    "\n",
    "    def load_all(self):\n",
    "        \"\"\"Đọc toàn bộ dữ liệu từ tất cả các shards\"\"\"\n",
    "        all_data = {}\n",
    "        for file_path in self.shards.values():\n",
    "            all_data.update(self.load_shard(file_path))\n",
    "        return all_data\n",
    "\n",
    "# ------------------ Test ------------------\n",
    "manager = PickleShardManager(num_shards=3)\n",
    "\n",
    "# Lưu dữ liệu\n",
    "manager.save(\"1\", {\"name\": \"Alice\", \"age\": 25})\n",
    "manager.save(\"2\", {\"product\": \"Laptop\", \"price\": 1200})\n",
    "\n",
    "# Kiểm tra key có tồn tại không (siêu nhanh)\n",
    "print(manager.exists(\"1\"))  # Output: True\n",
    "print(manager.exists(\"2\"))  # Output: True\n",
    "print(manager.exists(\"product999\"))  # Output: False\n",
    "\n",
    "# Cập nhật dữ liệu\n",
    "manager.update(\"user123\", {\"name\": \"Alice\", \"age\": 26})\n",
    "\n",
    "# Load toàn bộ dữ liệu\n",
    "print(manager.load_all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "pool = PoolManager(pool_id=1, pool_values=[10.5, 20.3, 30.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.save_pickle(file_path=\"./data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pool_id': 1, 'pool_values': [10.5, 20.3, 30.7]}\n"
     ]
    }
   ],
   "source": [
    "pool.read_pickle(file_path=\"./data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
